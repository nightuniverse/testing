#!/usr/bin/env python3
"""
test_excels í´ë”ì˜ ì—‘ì…€ íŒŒì¼ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ëŒ€ì•ˆ ì¿¼ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TestExcelQuerySystem:
    """test_excels í´ë”ì˜ ì—‘ì…€ íŒŒì¼ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì¿¼ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.test_excels_dir = Path("test_excels")
        self.results_dir = Path("test_excels/test_results")
        self.query_results_dir = self.results_dir / "query_results"
        self.query_results_dir.mkdir(exist_ok=True)
        
        # OpenAI API ì„¤ì •
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ëŒ€ì•ˆ ì¿¼ë¦¬ ì†”ë£¨ì…˜ ì„í¬íŠ¸
        from alternative_query_solutions import AlternativeQuerySolutions
        self.query_solutions = AlternativeQuerySolutions(str(self.results_dir))
    
    async def run_complete_test(self):
        """ì™„ì „í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ **test_excels í´ë” ì¿¼ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸**")
        print("=" * 80)
        
        # 1. ì—‘ì…€ íŒŒì¼ í™•ì¸
        excel_files = await self.get_excel_files()
        print(f"ğŸ“Š ì²˜ë¦¬í•  ì—‘ì…€ íŒŒì¼: {len(excel_files)}ê°œ")
        for file in excel_files:
            print(f"   - {file.name}")
        
        # 2. í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜
        test_queries = await self.define_test_queries()
        print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
        for i, query in enumerate(test_queries, 1):
            print(f"   {i}. {query}")
        
        # 3. ê° ì—‘ì…€ íŒŒì¼ë³„ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        all_results = {}
        
        for excel_file in excel_files:
            print(f"\nğŸ“„ **ì—‘ì…€ íŒŒì¼ í…ŒìŠ¤íŠ¸: {excel_file.name}**")
            print("=" * 60)
            
            file_results = await self.test_single_excel_file(excel_file, test_queries)
            all_results[excel_file.name] = file_results
            
            # ê°œë³„ íŒŒì¼ ê²°ê³¼ ì €ì¥
            await self.save_file_results(excel_file.name, file_results)
        
        # 4. ì¢…í•© ê²°ê³¼ ìƒì„± ë° ì €ì¥
        await self.save_comprehensive_results(all_results, test_queries)
        
        # 5. ê²°ê³¼ ìš”ì•½
        await self.print_test_summary(all_results, test_queries)
    
    async def get_excel_files(self) -> List[Path]:
        """test_excels í´ë”ì—ì„œ ì—‘ì…€ íŒŒì¼ ì°¾ê¸°"""
        excel_files = []
        
        if self.test_excels_dir.exists():
            for file_path in self.test_excels_dir.glob("*.xlsx"):
                if not file_path.name.startswith('~$'):  # ì„ì‹œ íŒŒì¼ ì œì™¸
                    excel_files.append(file_path)
        
        return excel_files
    
    async def define_test_queries(self) -> List[str]:
        """í…ŒìŠ¤íŠ¸ìš© ì¿¼ë¦¬ ì •ì˜"""
        return [
            "ì¡°ë¦½ ë‹¤ì´ì–´ê·¸ë¨ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ìˆ˜ì…ê²€ì‚¬ ê´€ë ¨ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì´ë¯¸ì§€ íŒŒì¼ì˜ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ê°€ìš”?",
            "í…Œì´ë¸” ë°ì´í„°ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”",
            "ì¡°ë¦½ ì‘ì—…í‘œì¤€ì„œì˜ ì£¼ìš” ë‚´ìš©ì€?",
            "ìƒì„±í˜• AI ì—°ë™ ìë£Œì˜ í•µì‹¬ ì •ë³´ëŠ”?",
            "ì—‘ì…€ íŒŒì¼ì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€ ê°œìˆ˜ëŠ”?",
            "ì¡°ë¦½ íŒŒíŠ¸ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”",
            "í’ˆì§ˆ ê´€ë¦¬ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ë˜ì–´ìˆë‚˜ìš”?",
            "ì‘ì—… ìˆœì„œë‚˜ ë‹¨ê³„ë³„ ì •ë³´ê°€ ìˆë‚˜ìš”?"
        ]
    
    async def test_single_excel_file(self, excel_file: Path, test_queries: List[str]) -> Dict[str, Any]:
        """ë‹¨ì¼ ì—‘ì…€ íŒŒì¼ì— ëŒ€í•œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
        
        file_results = {
            "file_name": excel_file.name,
            "file_size": excel_file.stat().st_size,
            "test_timestamp": datetime.now().isoformat(),
            "queries": {}
        }
        
        # íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì¿¼ë¦¬ í•„í„°ë§ìš©)
        file_keywords = self.extract_file_keywords(excel_file.name)
        
        for i, query in enumerate(test_queries, 1):
            print(f"   ğŸ” ì¿¼ë¦¬ {i}/{len(test_queries)}: {query}")
            
            query_results = {}
            
            try:
                # 1. ì§ì ‘ JSON ê²€ìƒ‰
                print("     1ï¸âƒ£ ì§ì ‘ JSON ê²€ìƒ‰...")
                result1 = await self.query_solutions.solution1_direct_json_query(
                    query, excel_file.stem
                )
                query_results["direct_json"] = {
                    "answer": result1.get("answer", ""),
                    "total_matches": result1.get("total_matches", 0),
                    "status": "success" if "error" not in result1 else "error",
                    "error": result1.get("error", None)
                }
                
                # 2. ì˜ë¯¸ì  ê²€ìƒ‰
                print("     2ï¸âƒ£ ì˜ë¯¸ì  ê²€ìƒ‰...")
                result2 = await self.query_solutions.solution2_semantic_search(
                    query, excel_file.stem
                )
                query_results["semantic_search"] = {
                    "answer": result2.get("answer", ""),
                    "total_chunks": result2.get("total_chunks", 0),
                    "top_similarity": result2.get("top_similarity", 0),
                    "status": "success" if "error" not in result2 else "error",
                    "error": result2.get("error", None)
                }
                
                # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
                print("     3ï¸âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰...")
                result3 = await self.query_solutions.solution3_hybrid_search(
                    query, excel_file.stem
                )
                query_results["hybrid_search"] = {
                    "answer": result3.get("answer", ""),
                    "keyword_matches": len(result3.get("keyword_results", {}).get("search_results", [])),
                    "semantic_matches": len(result3.get("semantic_results", {}).get("search_results", [])),
                    "status": "success" if "error" not in result3 else "error",
                    "error": result3.get("error", None)
                }
                
                # 4. Knowledge Graph ì¿¼ë¦¬
                print("     4ï¸âƒ£ Knowledge Graph ì¿¼ë¦¬...")
                result4 = await self.query_solutions.solution4_knowledge_graph_query(
                    query, excel_file.stem
                )
                query_results["knowledge_graph"] = {
                    "answer": result4.get("answer", ""),
                    "total_nodes": result4.get("total_nodes", 0),
                    "total_edges": result4.get("total_edges", 0),
                    "relevant_nodes": len(result4.get("kg_analysis", {}).get("relevant_nodes", [])),
                    "status": "success" if "error" not in result4 else "error",
                    "error": result4.get("error", None)
                }
                
                # 5. ìµœì  ë‹µë³€ ì„ íƒ
                best_answer = self.select_best_answer(query_results)
                query_results["best_answer"] = best_answer
                
            except Exception as e:
                print(f"     âŒ ì¿¼ë¦¬ {i} ì‹¤íŒ¨: {e}")
                query_results["error"] = str(e)
            
            file_results["queries"][f"query_{i}"] = {
                "question": query,
                "results": query_results
            }
            
            print(f"     âœ… ì¿¼ë¦¬ {i} ì™„ë£Œ")
        
        return file_results
    
    def extract_file_keywords(self, file_name: str) -> List[str]:
        """íŒŒì¼ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # íŒŒì¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_name = file_name.lower().replace('.xlsx', '').replace('(', ' ').replace(')', ' ')
        
        # ì£¼ìš” í‚¤ì›Œë“œë“¤
        key_terms = [
            "ì¡°ë¦½", "ì‘ì—…í‘œì¤€ì„œ", "ìˆ˜ì…ê²€ì‚¬", "ìƒì„±í˜•", "AI", "ì—°ë™", "íŒŒíŠ¸", "ìë£Œ",
            "FRONT", "DECO", "SUB", "SM-F741U", "B6"
        ]
        
        for term in key_terms:
            if term.lower() in clean_name:
                keywords.append(term)
        
        return keywords
    
    def select_best_answer(self, query_results: Dict[str, Any]) -> Dict[str, Any]:
        """ê°€ì¥ ì¢‹ì€ ë‹µë³€ ì„ íƒ"""
        best_answer = {
            "method": "none",
            "answer": "(no-context)",
            "confidence": 0.0,
            "reason": "ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨"
        }
        
        # ê° ë°©ë²•ë³„ ì ìˆ˜ ê³„ì‚°
        scores = {}
        
        # 1. ì§ì ‘ JSON ê²€ìƒ‰
        if "direct_json" in query_results:
            direct_result = query_results["direct_json"]
            if direct_result["status"] == "success" and direct_result["total_matches"] > 0:
                scores["direct_json"] = min(direct_result["total_matches"] * 0.1, 1.0)
        
        # 2. ì˜ë¯¸ì  ê²€ìƒ‰
        if "semantic_search" in query_results:
            semantic_result = query_results["semantic_search"]
            if semantic_result["status"] == "success" and semantic_result["top_similarity"] > 0:
                scores["semantic_search"] = semantic_result["top_similarity"]
        
        # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        if "hybrid_search" in query_results:
            hybrid_result = query_results["hybrid_search"]
            if hybrid_result["status"] == "success":
                total_matches = hybrid_result["keyword_matches"] + hybrid_result["semantic_matches"]
                scores["hybrid_search"] = min(total_matches * 0.05, 1.0)
        
        # 4. Knowledge Graph ì¿¼ë¦¬
        if "knowledge_graph" in query_results:
            kg_result = query_results["knowledge_graph"]
            if kg_result["status"] == "success" and kg_result["relevant_nodes"] > 0:
                scores["knowledge_graph"] = min(kg_result["relevant_nodes"] * 0.2, 1.0)
        
        # ìµœê³  ì ìˆ˜ ë°©ë²• ì„ íƒ
        if scores:
            best_method = max(scores, key=scores.get)
            best_score = scores[best_method]
            
            if best_score > 0:
                best_answer = {
                    "method": best_method,
                    "answer": query_results[best_method]["answer"],
                    "confidence": best_score,
                    "reason": f"{best_method}ì—ì„œ ê°€ì¥ ë†’ì€ ì ìˆ˜ ({best_score:.3f})"
                }
        
        return best_answer
    
    async def save_file_results(self, file_name: str, file_results: Dict[str, Any]):
        """ê°œë³„ íŒŒì¼ ê²°ê³¼ ì €ì¥"""
        output_file = self.query_results_dir / f"{file_name}_query_results.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(file_results, f, ensure_ascii=False, indent=2)
        
        print(f"   ğŸ’¾ íŒŒì¼ ê²°ê³¼ ì €ì¥: {output_file}")
    
    async def save_comprehensive_results(self, all_results: Dict[str, Any], test_queries: List[str]):
        """ì¢…í•© ê²°ê³¼ ì €ì¥"""
        
        # í†µê³„ ê³„ì‚°
        stats = {
            "total_files": len(all_results),
            "total_queries": len(test_queries),
            "test_timestamp": datetime.now().isoformat(),
            "file_statistics": {},
            "query_statistics": {},
            "method_performance": {
                "direct_json": {"success": 0, "total": 0},
                "semantic_search": {"success": 0, "total": 0},
                "hybrid_search": {"success": 0, "total": 0},
                "knowledge_graph": {"success": 0, "total": 0}
            }
        }
        
        # íŒŒì¼ë³„ í†µê³„
        for file_name, file_result in all_results.items():
            file_stats = {
                "file_size": file_result["file_size"],
                "queries_processed": len(file_result["queries"]),
                "best_answers": 0,
                "no_context_answers": 0
            }
            
            for query_key, query_data in file_result["queries"].items():
                results = query_data["results"]
                
                # ë°©ë²•ë³„ ì„±ê³µë¥  ê³„ì‚°
                for method in stats["method_performance"]:
                    if method in results:
                        stats["method_performance"][method]["total"] += 1
                        if results[method]["status"] == "success":
                            stats["method_performance"][method]["success"] += 1
                
                # ìµœì  ë‹µë³€ ë¶„ì„
                if "best_answer" in results:
                    best_answer = results["best_answer"]
                    if best_answer["method"] != "none":
                        file_stats["best_answers"] += 1
                    else:
                        file_stats["no_context_answers"] += 1
            
            stats["file_statistics"][file_name] = file_stats
        
        # ì¿¼ë¦¬ë³„ í†µê³„
        for i, query in enumerate(test_queries, 1):
            query_key = f"query_{i}"
            query_stats = {
                "question": query,
                "files_processed": 0,
                "successful_answers": 0,
                "no_context_answers": 0,
                "best_methods": {}
            }
            
            for file_name, file_result in all_results.items():
                if query_key in file_result["queries"]:
                    query_stats["files_processed"] += 1
                    
                    best_answer = file_result["queries"][query_key]["results"].get("best_answer", {})
                    if best_answer["method"] != "none":
                        query_stats["successful_answers"] += 1
                        method = best_answer["method"]
                        query_stats["best_methods"][method] = query_stats["best_methods"].get(method, 0) + 1
                    else:
                        query_stats["no_context_answers"] += 1
            
            stats["query_statistics"][query_key] = query_stats
        
        # ì„±ê³µë¥  ê³„ì‚°
        for method, performance in stats["method_performance"].items():
            if performance["total"] > 0:
                performance["success_rate"] = performance["success"] / performance["total"]
            else:
                performance["success_rate"] = 0
        
        # ì¢…í•© ê²°ê³¼ ì €ì¥
        comprehensive_results = {
            "test_summary": stats,
            "detailed_results": all_results,
            "test_queries": test_queries
        }
        
        output_file = self.query_results_dir / "comprehensive_query_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì¢…í•© ê²°ê³¼ ì €ì¥: {output_file}")
    
    async def print_test_summary(self, all_results: Dict[str, Any], test_queries: List[str]):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š **í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½**")
        print("=" * 80)
        
        print(f"ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼: {len(all_results)}ê°œ")
        print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
        
        # íŒŒì¼ë³„ ìš”ì•½
        print(f"\nğŸ“„ **íŒŒì¼ë³„ ê²°ê³¼**")
        for file_name, file_result in all_results.items():
            file_size_mb = file_result["file_size"] / (1024 * 1024)
            print(f"   {file_name} ({file_size_mb:.1f}MB)")
            
            # ì¿¼ë¦¬ ì„±ê³µë¥  ê³„ì‚°
            total_queries = len(file_result["queries"])
            successful_queries = sum(
                1 for query_data in file_result["queries"].values()
                if query_data["results"].get("best_answer", {}).get("method") != "none"
            )
            success_rate = (successful_queries / total_queries) * 100 if total_queries > 0 else 0
            
            print(f"     ì„±ê³µë¥ : {success_rate:.1f}% ({successful_queries}/{total_queries})")
        
        # ë°©ë²•ë³„ ì„±ëŠ¥
        print(f"\nğŸ”§ **ë°©ë²•ë³„ ì„±ëŠ¥**")
        method_counts = {"direct_json": 0, "semantic_search": 0, "hybrid_search": 0, "knowledge_graph": 0}
        
        for file_result in all_results.values():
            for query_data in file_result["queries"].values():
                best_method = query_data["results"].get("best_answer", {}).get("method", "none")
                if best_method in method_counts:
                    method_counts[best_method] += 1
        
        total_queries = sum(method_counts.values())
        for method, count in method_counts.items():
            percentage = (count / total_queries) * 100 if total_queries > 0 else 0
            print(f"   {method}: {count}íšŒ ({percentage:.1f}%)")
        
        print(f"\nâœ… **í…ŒìŠ¤íŠ¸ ì™„ë£Œ**")
        print(f"   ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.query_results_dir}")

# ë©”ì¸ í•¨ìˆ˜
async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        test_system = TestExcelQuerySystem()
        
        # ì™„ì „í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        await test_system.run_complete_test()
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
