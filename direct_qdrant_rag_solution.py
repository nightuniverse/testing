#!/usr/bin/env python3
"""
ì§ì ‘ Qdrant ì‚¬ìš©ìœ¼ë¡œ rag-anything ìš°íšŒ - ì™„ì „í•œ RAG ì†”ë£¨ì…˜
"""

import asyncio
import os
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import uuid
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DirectQdrantRAG:
    """ì§ì ‘ Qdrant ì‚¬ìš© RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, collection_name: str = "manufacturing_docs"):
        self.collection_name = collection_name
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        self.qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            from qdrant_client import QdrantClient
            self.client = QdrantClient(url=self.qdrant_url)
            print(f"âœ… Qdrant ì—°ê²° ì„±ê³µ: {self.qdrant_url}")
        except Exception as e:
            print(f"âŒ Qdrant ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
        
        # OpenAI ì„ë² ë”© ëª¨ë¸
        try:
            from langchain_openai import OpenAIEmbeddings
            self.embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",
                openai_api_key=self.openai_api_key,
                openai_api_base=self.openai_base_url
            )
            print("âœ… OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        # Docling íŒŒì„œ
        try:
            from docling import DoclingParser
            self.parser = DoclingParser()
            print("âœ… Docling íŒŒì„œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ Docling íŒŒì„œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        # ì»¬ë ‰ì…˜ ì„¤ì •
        self._setup_collection()
    
    def _setup_collection(self):
        """ì»¬ë ‰ì…˜ ì„¤ì •"""
        try:
            from qdrant_client.models import Distance, VectorParams
            
            # ì»¬ë ‰ì…˜ ìƒì„±
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(size=1536, distance=Distance.COSINE),
            )
            print(f"âœ… ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")
        except Exception as e:
            print(f"â„¹ï¸ ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {e}")
    
    def _split_text_into_chunks(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ì˜¤ë²„ë© í¬í•¨)"""
        if not text or len(text) <= chunk_size:
            return [text] if text else []
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            if end < len(text):
                # ë§ˆì§€ë§‰ ê³µë°±ì´ë‚˜ ë¬¸ì¥ ë¶€í˜¸ë¥¼ ì°¾ì•„ì„œ ìë¥´ê¸°
                last_space = text.rfind(' ', start, end)
                last_period = text.rfind('.', start, end)
                last_newline = text.rfind('\n', start, end)
                
                cut_point = max(last_space, last_period, last_newline)
                if cut_point > start:
                    end = cut_point + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # ì˜¤ë²„ë©ì„ ê³ ë ¤í•œ ë‹¤ìŒ ì‹œì‘ì 
            start = max(start + 1, end - overlap)
        
        return chunks
    
    async def process_document(self, file_path: str) -> Dict[str, Any]:
        """ë¬¸ì„œ ì²˜ë¦¬ ë° Qdrant ì €ì¥"""
        try:
            print(f"ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬: {file_path}")
            
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not Path(file_path).exists():
                return {"status": "error", "message": f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}"}
            
            # 1. Doclingìœ¼ë¡œ íŒŒì‹±
            print("   ğŸ”„ Docling íŒŒì‹± ì¤‘...")
            result = await self.parser.parse_document(file_path)
            
            if not result or "content" not in result:
                return {"status": "error", "message": "íŒŒì‹± ì‹¤íŒ¨ - contentê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # 2. í…ìŠ¤íŠ¸ ì²­í‚¹
            content = result["content"]
            chunks = self._split_text_into_chunks(content)
            
            print(f"   ì²­í¬ ìˆ˜: {len(chunks)}")
            
            if not chunks:
                return {"status": "error", "message": "ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
            
            # 3. ì„ë² ë”© ìƒì„± ë° ì €ì¥
            print("   ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...")
            points = []
            
            for i, chunk in enumerate(chunks):
                try:
                    # ì„ë² ë”© ìƒì„±
                    embedding = self.embeddings.embed_query(chunk)
                    
                    # í¬ì¸íŠ¸ ìƒì„±
                    from qdrant_client.models import PointStruct
                    point = PointStruct(
                        id=str(uuid.uuid4()),
                        vector=embedding,
                        payload={
                            "text": chunk,  # í†µì¼ëœ í•„ë“œëª…
                            "doc_id": Path(file_path).stem,
                            "chunk_index": i,
                            "file_path": file_path,
                            "source": "docling",
                            "chunk_size": len(chunk)
                        }
                    )
                    points.append(point)
                    
                    if (i + 1) % 10 == 0:
                        print(f"     {i + 1}/{len(chunks)} ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ")
                        
                except Exception as e:
                    print(f"     ì²­í¬ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            if not points:
                return {"status": "error", "message": "ì €ì¥í•  í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # 4. Qdrantì— ì €ì¥
            print("   ğŸ”„ Qdrantì— ì €ì¥ ì¤‘...")
            self.client.upsert(
                collection_name=self.collection_name,
                points=points
            )
            
            print(f"âœ… {len(points)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")
            
            return {
                "status": "success",
                "chunks": len(chunks),
                "points_stored": len(points),
                "file_path": file_path,
                "doc_id": Path(file_path).stem
            }
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"status": "error", "message": str(e)}
    
    async def query(self, question: str, top_k: int = 5, score_threshold: float = 0.0) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            print(f"ğŸ” ì¿¼ë¦¬: {question}")
            
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            print("   ğŸ”„ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì¤‘...")
            query_embedding = self.embeddings.embed_query(question)
            
            # 2. Qdrantì—ì„œ ê²€ìƒ‰
            print("   ğŸ”„ Qdrant ê²€ìƒ‰ ì¤‘...")
            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                limit=top_k,
                score_threshold=score_threshold
            )
            
            print(f"   ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(search_results)}")
            
            # 3. ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            contexts = []
            for i, result in enumerate(search_results):
                context = {
                    "rank": i + 1,
                    "score": result.score,
                    "text": result.payload.get("text", ""),
                    "doc_id": result.payload.get("doc_id", ""),
                    "chunk_index": result.payload.get("chunk_index", 0),
                    "file_path": result.payload.get("file_path", "")
                }
                contexts.append(context)
                print(f"   ê²°ê³¼ {i+1}: ì ìˆ˜={result.score:.4f}, í…ìŠ¤íŠ¸={result.payload.get('text', '')[:50]}...")
            
            # 4. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
            if contexts:
                print("   ğŸ”„ LLM ë‹µë³€ ìƒì„± ì¤‘...")
                context_text = "\n\n".join([ctx["text"] for ctx in contexts])
                
                import openai
                client = openai.OpenAI(
                    api_key=self.openai_api_key,
                    base_url=self.openai_base_url
                )
                
                prompt = f"""ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context_text}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
                
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=1000,
                    temperature=0
                )
                
                answer = response.choices[0].message.content
            else:
                answer = "(no-context)"
                print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ (no-context) ë°˜í™˜")
            
            return {
                "question": question,
                "answer": answer,
                "contexts": contexts,
                "total_results": len(search_results),
                "top_k": top_k,
                "score_threshold": score_threshold
            }
            
        except Exception as e:
            print(f"âŒ ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "question": question,
                "answer": f"ì˜¤ë¥˜ ë°œìƒ: {e}",
                "contexts": [],
                "total_results": 0,
                "error": str(e)
            }
    
    def get_collection_info(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ"""
        try:
            collection_info = self.client.get_collection(self.collection_name)
            return {
                "collection_name": self.collection_name,
                "points_count": collection_info.points_count,
                "vector_size": collection_info.config.params.vectors.size,
                "distance_metric": collection_info.config.params.vectors.distance
            }
        except Exception as e:
            return {"error": str(e)}
    
    def clear_collection(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ì´ˆê¸°í™”"""
        try:
            self.client.delete_collection(self.collection_name)
            self._setup_collection()
            return {"status": "success", "message": "ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤"}
        except Exception as e:
            return {"status": "error", "message": str(e)}

# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì‚¬ìš© ì˜ˆì‹œ"""
    print("ğŸš€ **ì§ì ‘ Qdrant RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸**")
    print("=" * 60)
    
    try:
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag = DirectQdrantRAG()
        
        # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
        collection_info = rag.get_collection_info()
        print(f"ğŸ“Š ì»¬ë ‰ì…˜ ì •ë³´: {collection_info}")
        
        # ë¬¸ì„œ ì²˜ë¦¬ (ì„ íƒì )
        data_dir = Path("data")
        if data_dir.exists():
            pdf_files = list(data_dir.glob("*.pdf"))
            if pdf_files:
                test_file = pdf_files[0]
                print(f"\nğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_file}")
                
                # ë¬¸ì„œ ì²˜ë¦¬
                result = await rag.process_document(str(test_file))
                print(f"ë¬¸ì„œ ì²˜ë¦¬ ê²°ê³¼: {result}")
                
                if result["status"] == "success":
                    # ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
                    test_queries = [
                        "ë§¤ì¶œì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?",
                        "ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”",
                        "ì œì¡°ì—… ê´€ë ¨ ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                    ]
                    
                    for query in test_queries:
                        print(f"\nğŸ” ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸: {query}")
                        query_result = await rag.query(query, top_k=5)
                        print(f"ë‹µë³€: {query_result['answer']}")
                        print(f"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {query_result['total_results']}")
        else:
            print("ğŸ“ data ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì¿¼ë¦¬ë§Œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        
        # ë¹ˆ ì»¬ë ‰ì…˜ì—ì„œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ” ë¹ˆ ì»¬ë ‰ì…˜ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸")
        query_result = await rag.query("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸", top_k=5)
        print(f"ê²°ê³¼: {query_result['answer']}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    asyncio.run(main())
